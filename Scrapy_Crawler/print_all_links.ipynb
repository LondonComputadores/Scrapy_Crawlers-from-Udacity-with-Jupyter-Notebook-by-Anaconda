{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page(url):\n",
    "    try:\n",
    "        if url == \"Paste url here!\":\n",
    "            return ('<html><body> This is a crawler.'\n",
    "            '<p> It is a nice crawler'\n",
    "            '<a href = \"Paste a sub url1 here!\"> Carry on! </a> Just do it!'\n",
    "            '<a href = \"Paste a sub url2 here!\"> Carry on 2! </a>' or \n",
    "                    '<a href = \"Paste a sub url1 here!\"> Carry on! </a> Just do it!'\n",
    "                    '</p></body></html>')\n",
    "        elif url == \"Paste a sub url1 here again\":\n",
    "            return ('<html><body> I have not got this all yet'\n",
    "                   '<a href = \"Paste a sub url 3 here!\"> Doing </a>'\n",
    "                   '</body></html>')\n",
    "        elif url == \"Paste a sub url 2 here again!\":\n",
    "            return ('<html><body> I cannot get enough!'\n",
    "                   '<a href = \"Paste the very first url here!\"> Crawling </a>'\n",
    "                   '</body></html>')\n",
    "        elif url == \"Paste a sub url 4 here!\":\n",
    "            return ('<html><body> The magic world are earth and mars!'\n",
    "                   '</body></html>')\n",
    "except:\n",
    "    return \" \"\n",
    "return\n",
    "\n",
    "def get_next_target(page):\n",
    "    start_link = page.find('<a href = ')\n",
    "    if start_link == -1:\n",
    "        return None, 0\n",
    "    start_quote = page.find(\"\",start_link)\n",
    "    end_quote = page.find(\"\",start_quote+1)\n",
    "    url = page [start_quote+1:end_quote]\n",
    "    return url, end_quote\n",
    "\n",
    "def union(p,q):\n",
    "    for e in q:\n",
    "        if e not in p:\n",
    "            p.append(e)\n",
    "            \n",
    "def get_all_links(page):\n",
    "    links = []\n",
    "    while True:\n",
    "        url, endpos = get_next_target(page)\n",
    "        if url:\n",
    "            links.append(url)\n",
    "            page = page [endpos:]\n",
    "        else:\n",
    "            break\n",
    "    return links\n",
    "\n",
    "def crawl_web(seed,max_pages):\n",
    "    tocrawl = [seed]\n",
    "    crawled = []\n",
    "    while tocrawl:\n",
    "        page = tocrawl.pop()\n",
    "        if page not in crawled:\n",
    "            union(tocrawl, get_all_links(get_page(page)))\n",
    "    return crawled\n",
    "\n",
    "print crawl_web(\"Paste here the very first url again\", 10 ) #ou 500 ou as many links as you like since it's an integer!\n",
    "\n",
    "def crawl_web(seed,max_depth):\n",
    "    tocrawl = [seed]\n",
    "    crawled = []\n",
    "    next_depth = []\n",
    "    depth = 0\n",
    "    while tocrawl and depth <= max_depth:\n",
    "        page = tocrawl.pop()\n",
    "        if page not in crawled:\n",
    "            union(next_depth, get_all_links(get_page(page)))\n",
    "            crawled.append(page)\n",
    "            if not tocrawl:\n",
    "                tocrawl, next_depth = next_depth, []\n",
    "                depth = depth+1\n",
    "    return crawled\n",
    "\n",
    "print crawl_web(\"Paste here the very first url again\", 50 )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
